# -*- coding: utf-8 -*-
"""Copy of transformerRE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YxbGe-rpt3B3eq635NxMd3YzcMGwtnBx
"""

from google.colab import drive
drive.mount('/content/drive')

PATH = '/content/drive/My Drive/'
device = 'cuda'
import torch
if torch.cuda.is_available():
  device = 'cuda'
else:
  device = 'cpu'
print(device)

#load data
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from pandas import read_csv

output_window = 1

def get_data():
    data = []
    features = []
    location = []
    label = []
    series = read_csv(PATH +'DATA/data_census_update.csv', sep=',', header=None, low_memory=False, keep_default_na=False).to_numpy()

    for i in range(len(series)):
        if i == 0:
            continue

        # if '' in series[i]:
        #   continue

        line = series[i][2:-11]
        line = [float(_) if _ != '' else -1 for _ in line]
        line = [int(j) for j in line]

        data.append(line)

        f = series[i][-11:-1]
        f = [float(_) if _ != '' else -1 for _ in f]
        f = [int(_) for _ in f]

        features.append(f)

        label.append(int(float(series[i][-1])))
        
    data = np.asarray(data)
    features = np.asarray(features)
    label = np.asarray(label)
    
    data_ = []
    features_ = []
    for i in range(len(data)):
        scaler = MinMaxScaler(feature_range=(0, 1)) 
        x = data[i]
        x = scaler.fit_transform(np.array(x).reshape(-1, 1)).reshape(-1)
        data_.append(x)

        features_.append(scaler.fit_transform(np.array(features[i]).reshape(-1, 1)).reshape(-1))

    input_data = torch.FloatTensor(data_)
    label = torch.FloatTensor(label)
    features = torch.FloatTensor(features_)

    samples = int(len(input_data)*0.7)
    x_train = input_data[:samples]
    x_test = input_data[samples:]
        
    y_train = label[:samples]
    y_test = label[samples:]

    ftr_train = features[:samples]
    ftr_test = features[samples:]

    return x_train, y_train, ftr_train, x_test, y_test, ftr_test

if __name__ == '__main__':
    x_train, y_train, ftr_train, x_test, y_test, ftr_test = get_data()
    print(x_train.shape)
    print(y_train.shape)
    print(ftr_train.shape)

    print(x_test.shape)
    print(y_test.shape)
    print(ftr_test.shape)

    pass

##Transformer
from __future__ import print_function
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import argparse
import sys
import math

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, max_len=5000,**block_args):
        super(PositionalEncoding, self).__init__()       
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        pe.requires_grad = True
        self.register_buffer('pe', pe)
        #self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(num_layers)])

    def forward(self, x):
        return x + self.pe[:x.size(0), :]

    def get_attention_maps(self, x, mask=None):
        attention_maps = []
        for l in self.layers:
            _, attn_map = l.self_attn(x, mask=mask, return_attention=True)
            attention_maps.append(attn_map)
            x = l(x)
        return attention_maps

class Transformer(nn.Module):
    def __init__(self, input_size, feature_size=250,num_layers=1,dropout=0.1):
        super(Transformer, self).__init__()
        self.src_mask = None
        self.pos_encoder = PositionalEncoding(feature_size)
        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)
        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        
        
        self.layer = nn.Linear(feature_size,1) 
        self.layer1 = nn.Linear(input_size, 200)
        self.layer2 = nn.Linear(200, 100)
        self.layer3 = nn.Linear(100, 1)

        self.last_layer = nn.Sigmoid()
       
     
    def forward(self, src, ftr):
        if self.src_mask is None or self.src_mask.size(0) != len(src):
            mask = self._generate_square_subsequent_mask(len(src)).to(device)
            self.src_mask = mask

        src = self.pos_encoder(src)
        hidden = self.transformer_encoder(src,self.src_mask)

        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], hidden.shape[2])

        hidden = torch.cat((hidden, ftr), 0)

        output = self.layer(hidden)

        output = torch.squeeze(output)
        output = output.transpose(0, 1)

        output = self.layer1(output)
        output = self.layer2(output)
        output = self.layer3(output)

        output = self.last_layer(output)
        return output

    def _generate_square_subsequent_mask(self, sz):
        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)
        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))
        return mask


if __name__ == '__main__':
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument('--mode', choices=['train', 'infer'],\
        default='train',help='Run mode')
    arg_parser.add_argument('--epoch', default='30', type=int)
    arg_parser.add_argument('--batch_size', default='32', type=int)
    args = arg_parser.parse_args(args=['--mode', 'train'])
    args = arg_parser.parse_args(args=['--epoch', '30'])
    args = arg_parser.parse_args(args=['--batch_size', '32'])

    model_path = PATH + 'MODEL/model_all_transformer_12.pt'

    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()

    print(X_train.shape)
    print(y_train.shape)
    print(X_test.shape)
    print(y_test.shape)

    model = Transformer(input_size = X_train.shape[1] + FTR_train.shape[1])
    loss_function = nn.MSELoss()

    #map = model.get_attention_maps(X_train)
    #print(map)

    optimizer = optim.SGD(model.parameters(), lr=0.1)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)

    num_batch = int(len(y_train)/args.batch_size) + 1

    num_batch_test = int(len(y_test)/args.batch_size) + 1

    last_acc = 0.0

    if args.mode == 'train':

        for epoch in range(args.epoch):
           
            acc = []
            total_loss = 0

            acc_test = []

            model.to(device)
            
            for i in range(num_batch):
                sys.stdout.write('\r{0}/{1}'.format(i, num_batch))
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_train))

                x = X_train[st:ed]
                x = x.transpose(0, 1)
                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))
                x = x.to(device)

                ftr = FTR_train[st:ed]
                ftr = ftr.transpose(0, 1)
                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
                ftr = ftr.to(device)

                label = y_train[st:ed]
                label = label.to(device)

                model.zero_grad()

                output = model(x, ftr)
                predict = torch.squeeze(output)

                loss = loss_function(predict, label)
                
                acc.append(torch.sum(predict.gt(0.5) == label))
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            for i in range(num_batch_test):
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_test))

                x_test = X_test[st:ed]
                x_test = x_test.transpose(0, 1)
                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
                x_test = x_test.to(device)

                ftr_test = FTR_test[st:ed]
                ftr_test = ftr_test.transpose(0, 1)
                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
                ftr_test = ftr_test.to(device)

                label_test = y_test[st:ed]
                label_test = label_test.to(device)


                output_test = model(x_test, ftr_test)
                predict_test = torch.squeeze(output_test)
                acc_test.append(torch.sum(predict_test.gt(0.5) == label_test))
           
            total_loss /= len(y_train)
            acc = sum(acc)*1.0/len(y_train)

            acc_test = sum(acc_test)*1.0/len(y_test)
            if epoch%10 == 0 or epoch == args.epoch - 1:
              print('\nEpoch: ', epoch)
              print('\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))

            scheduler.step() 

            if acc_test > last_acc:
                torch.save(model.cpu(), model_path)
                last_acc = acc_test

pip install scikit-plot

#Transformer evaluation
from sklearn import metrics 
from sklearn.metrics import classification_report, confusion_matrix

model_path = PATH + 'MODEL/model_all_transformer_12.pt'
model = torch.load(model_path)
model.to(device)
acc_test = []
y_pred = []

for i in range(num_batch_test):
    st = i * args.batch_size
    ed = min((i+1) * args.batch_size, len(y_test))

    x_test = X_test[st:ed]
    x_test = x_test.transpose(0, 1)
    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
    x_test = x_test.to(device)

    ftr_test = FTR_test[st:ed]
    ftr_test = ftr_test.transpose(0, 1)
    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
    ftr_test = ftr_test.to(device)

    label_test = y_test[st:ed]
    label_test = label_test.to(device)


    output_test = model(x_test, ftr_test)
    predict_test = torch.squeeze(output_test)
    y_pred += predict_test.gt(0.5)

y_pred = list(map(float, y_pred))
y_pred = np.asarray(y_pred)
y_pred = torch.FloatTensor(y_pred)

print('Transformer Results:')
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(metrics.roc_auc_score(y_test, y_pred))
# calculate the fpr and tpr for all thresholds of the classification

fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)
roc_auc = metrics.auc(fpr, tpr)

# method I: plt
import matplotlib.pyplot as plt

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--',label='Sample Label Red')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.savefig(PATH+"roc.png")



#MLP baseline
from __future__ import print_function
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import argparse
import sys
import math

class MLP(nn.Module):
    def __init__(self, input_size):
        super(MLP, self).__init__()
        self.layer1 = nn.Linear(input_size, 200)
        self.layer2 = nn.Linear(200, 100)
        self.layer3 = nn.Linear(100, 1)

        self.last_layer = nn.Sigmoid() 
     
    def forward(self, src, ftr):
        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], src.shape[2])

        hidden = torch.cat((src, ftr), 0)

        output = torch.squeeze(hidden)
        output = output.transpose(0, 1)

        output = self.layer1(output)
        output = self.layer2(output)
        output = self.layer3(output)

        output = self.last_layer(output)
        return output

if __name__ == '__main__':
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument('--mode', choices=['train', 'infer'],\
        default='train',help='Run mode')
    arg_parser.add_argument('--epoch', default='30', type=int)
    arg_parser.add_argument('--batch_size', default='32', type=int)
    args = arg_parser.parse_args(args=['--mode', 'train'])
    args = arg_parser.parse_args(args=['--epoch', '30'])
    args = arg_parser.parse_args(args=['--batch_size', '32'])

    model_path_mlp = PATH + 'MODEL/model_mlp_temporal.pt'

    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()

    print(X_train.shape)
    print(y_train.shape)
    print(X_test.shape)
    print(y_test.shape)

    model = MLP(input_size = X_train.shape[1] + FTR_train.shape[1])
    loss_function = nn.MSELoss()

    optimizer = optim.SGD(model.parameters(), lr=0.1)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)

    num_batch = int(len(y_train)/args.batch_size) + 1

    num_batch_test = int(len(y_test)/args.batch_size) + 1

    last_acc = 0.0

    if args.mode == 'train':

        for epoch in range(args.epoch):
           
            acc = []
            total_loss = 0

            acc_test = []

            model.to(device)
            
            for i in range(num_batch):
                sys.stdout.write('\r{0}/{1}'.format(i, num_batch))
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_train))

                x = X_train[st:ed]
                x = x.transpose(0, 1)
                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))
                x = x.to(device)

                ftr = FTR_train[st:ed]
                ftr = ftr.transpose(0, 1)
                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
                ftr = ftr.to(device)

                label = y_train[st:ed]
                label = label.to(device)

                model.zero_grad()

                output = model(x, ftr)
                predict = torch.squeeze(output)

                loss = loss_function(predict, label)
                
                acc.append(torch.sum(predict.gt(0.5) == label))
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            for i in range(num_batch_test):
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_test))

                x_test = X_test[st:ed]
                x_test = x_test.transpose(0, 1)
                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
                x_test = x_test.to(device)

                ftr_test = FTR_test[st:ed]
                ftr_test = ftr_test.transpose(0, 1)
                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
                ftr_test = ftr_test.to(device)

                label_test = y_test[st:ed]
                label_test = label_test.to(device)


                output_test = model(x_test, ftr_test)
                predict_test = torch.squeeze(output_test)
                acc_test.append(torch.sum(predict_test.gt(0.5) == label_test))
           
            total_loss /= len(y_train)
            acc = sum(acc)*1.0/len(y_train)

            acc_test = sum(acc_test)*1.0/len(y_test)
            if epoch%10 == 0 or epoch == args.epoch - 1:
              print('\nEpoch: ', epoch)
              print('\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))

            scheduler.step() 

            if acc_test > last_acc:
                torch.save(model.cpu(), model_path_mlp)
                last_acc = acc_test

#MLP evaluation
from sklearn import metrics 
from sklearn.metrics import classification_report, confusion_matrix

model = torch.load(model_path_mlp)
model.to(device)
acc_test = []
y_pred = []

for i in range(num_batch_test):
    st = i * args.batch_size
    ed = min((i+1) * args.batch_size, len(y_test))

    x_test = X_test[st:ed]
    x_test = x_test.transpose(0, 1)
    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
    x_test = x_test.to(device)

    ftr_test = FTR_test[st:ed]
    ftr_test = ftr_test.transpose(0, 1)
    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
    ftr_test = ftr_test.to(device)

    label_test = y_test[st:ed]
    label_test = label_test.to(device)


    output_test = model(x_test, ftr_test)
    predict_test = torch.squeeze(output_test)
    y_pred += predict_test.gt(0.5)

y_pred = list(map(float, y_pred))
y_pred = np.asarray(y_pred)
y_pred = torch.FloatTensor(y_pred)

print('MLP Results:')
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(metrics.roc_auc_score(y_test, y_pred))

#LSTM baseline
from __future__ import print_function
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import argparse
import sys
import math

class LSTM(nn.Module):
    def __init__(self, input_size, feature_size=250,num_layers=1,dropout=0.1):
        super(LSTM, self).__init__()
        self.layer1 = nn.LSTM(input_size, 50)
        self.layer2 = nn.Linear(50, 1)

        self.last_layer = nn.Sigmoid()
     
    def forward(self, src, ftr):

        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], src.shape[2])

        hidden = torch.cat((src, ftr), 0)
        hidden = hidden.transpose(1, 2)
        hidden = hidden.transpose(0, 2)

        hidden, (hn, cn) = self.layer1(hidden)
        output = self.layer2(hidden)

        output = self.last_layer(output)
        return output

if __name__ == '__main__':
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument('--mode', choices=['train', 'infer'],\
        default='train',help='Run mode')
    arg_parser.add_argument('--epoch', default='30', type=int)
    arg_parser.add_argument('--batch_size', default='32', type=int)
    args = arg_parser.parse_args(args=['--mode', 'train'])
    args = arg_parser.parse_args(args=['--epoch', '30'])
    args = arg_parser.parse_args(args=['--batch_size', '32'])

    model_path_lstm = PATH + 'MODEL/model_lstm.pt'

    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()

    print(X_train.shape)
    print(y_train.shape)
    print(X_test.shape)
    print(y_test.shape)

    model = LSTM(input_size = X_train.shape[1] + FTR_train.shape[1])
    loss_function = nn.MSELoss()

    optimizer = optim.SGD(model.parameters(), lr=0.1)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)

    num_batch = int(len(y_train)/args.batch_size) + 1

    num_batch_test = int(len(y_test)/args.batch_size) + 1

    last_acc = 0.0

    if args.mode == 'train':

        for epoch in range(args.epoch):
           
            acc = []
            total_loss = 0

            acc_test = []

            model.to(device)
            
            for i in range(num_batch):
                sys.stdout.write('\r{0}/{1}'.format(i, num_batch))
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_train))

                x = X_train[st:ed]
                x = x.transpose(0, 1)
                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))
                x = x.to(device)

                ftr = FTR_train[st:ed]
                ftr = ftr.transpose(0, 1)
                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
                ftr = ftr.to(device)

                label = y_train[st:ed]
                label = label.to(device)

                model.zero_grad()

                output = model(x, ftr)
                predict = torch.squeeze(output)

                loss = loss_function(predict, label)
                
                acc.append(torch.sum(predict.gt(0.5) == label))
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            for i in range(num_batch_test):
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_test))

                x_test = X_test[st:ed]
                x_test = x_test.transpose(0, 1)
                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
                x_test = x_test.to(device)

                ftr_test = FTR_test[st:ed]
                ftr_test = ftr_test.transpose(0, 1)
                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
                ftr_test = ftr_test.to(device)

                label_test = y_test[st:ed]
                label_test = label_test.to(device)


                output_test = model(x_test, ftr_test)
                predict_test = torch.squeeze(output_test)
                acc_test.append(torch.sum(predict_test.gt(0.5) == label_test))
           
            total_loss /= len(y_train)
            acc = sum(acc)*1.0/len(y_train)

            acc_test = sum(acc_test)*1.0/len(y_test)
            if epoch%10 == 0 or epoch == args.epoch - 1:
              print('\nEpoch: ', epoch)
              print('\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))

            scheduler.step() 

            if acc_test > last_acc:
                torch.save(model.cpu(), model_path_lstm)
                last_acc = acc_test

#LSTM evaluation
from sklearn import metrics 
from sklearn.metrics import classification_report, confusion_matrix

model = torch.load(model_path_lstm)
model.to(device)
acc_test = []
y_pred = []

for i in range(num_batch_test):
    st = i * args.batch_size
    ed = min((i+1) * args.batch_size, len(y_test))

    x_test = X_test[st:ed]
    x_test = x_test.transpose(0, 1)
    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
    x_test = x_test.to(device)

    ftr_test = FTR_test[st:ed]
    ftr_test = ftr_test.transpose(0, 1)
    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
    ftr_test = ftr_test.to(device)

    label_test = y_test[st:ed]
    label_test = label_test.to(device)


    output_test = model(x_test, ftr_test)
    predict_test = torch.squeeze(output_test)
    y_pred += predict_test.gt(0.5)

y_pred = list(map(float, y_pred))
y_pred = np.asarray(y_pred)
y_pred = torch.FloatTensor(y_pred)

print('LSTM Results:')
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(metrics.roc_auc_score(y_test, y_pred))

#load data
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from pandas import read_csv

output_window = 1

def get_data():
    data = []
    features = []
    location = []
    label = []
    series = read_csv(PATH+'DATA/data_census_hotspot_2.csv', sep=',', header=None, low_memory=False, keep_default_na=False).to_numpy()

    for i in range(len(series)):
        if i == 0:
            continue

        # if '' in series[i]:
        #   continue

        line = series[i][2:-12]
        line = [float(_) if _ != '' else -1 for _ in line]
        line = [int(j) for j in line]

        data.append(line)

        f = series[i][-12:-2]
        f = [float(_) if _ != '' else -1 for _ in f]
        f = [int(_) for _ in f]

        features.append(f)
        
        idx = int(float(series[i][-1]))
        hotspot = [0.] * 4
        hotspot[idx] = 1.

        label.append(hotspot)
        
    data = np.asarray(data)
    features = np.asarray(features)
    label = np.asarray(label)
    
    data_ = []
    features_ = []
    for i in range(len(data)):
        scaler = MinMaxScaler(feature_range=(0, 1)) 
        x = data[i]
        x = scaler.fit_transform(np.array(x).reshape(-1, 1)).reshape(-1)
        data_.append(x)

        features_.append(scaler.fit_transform(np.array(features[i]).reshape(-1, 1)).reshape(-1))

    input_data = torch.FloatTensor(data_)
    label = torch.FloatTensor(label)
    features = torch.FloatTensor(features_)

    samples = int(len(input_data)*0.7)
    x_train = input_data[:samples]
    x_test = input_data[samples:]
        
    y_train = label[:samples]
    y_test = label[samples:]

    ftr_train = features[:samples]
    ftr_test = features[samples:]

    return x_train, y_train, ftr_train, x_test, y_test, ftr_test

if __name__ == '__main__':
    x_train, y_train, ftr_train, x_test, y_test, ftr_test = get_data()
    print(x_train.shape)
    print(y_train.shape)
    print(ftr_train.shape)

    print(x_test.shape)
    print(y_test.shape)
    print(ftr_test.shape)

    pass

#LSTM city prediction
from __future__ import print_function
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import argparse
import sys
import math

class LSTM(nn.Module):
    def __init__(self, input_size, feature_size=250,num_layers=1,dropout=0.1):
        super(LSTM, self).__init__()
        self.layer1 = nn.LSTM(input_size, 50)
        self.layer2 = nn.Linear(50, 4)

        self.last_layer = nn.Sigmoid()
     
    def forward(self, src, ftr):

        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], src.shape[2])

        hidden = torch.cat((src, ftr), 0)
        hidden = hidden.transpose(1, 2)
        hidden = hidden.transpose(0, 2)

        hidden, (hn, cn) = self.layer1(hidden)
        output = self.layer2(hidden)

        output = self.last_layer(output)
        return output

if __name__ == '__main__':
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument('--mode', choices=['train', 'infer'],\
        default='train',help='Run mode')
    arg_parser.add_argument('--epoch', default='100', type=int)
    arg_parser.add_argument('--batch_size', default='32', type=int)
    args = arg_parser.parse_args(args=['--mode', 'train'])
    args = arg_parser.parse_args(args=['--epoch', '100'])
    args = arg_parser.parse_args(args=['--batch_size', '32'])

    model_path_city_lstm = PATH + 'MODEL/model_lstm_city.pt'

    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()

    print(X_train.shape)
    print(y_train.shape)
    print(X_test.shape)
    print(y_test.shape)

    model = LSTM(input_size = X_train.shape[1] + FTR_train.shape[1])
    loss_function = nn.MSELoss()

    optimizer = optim.SGD(model.parameters(), lr=0.1)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)

    num_batch = int(len(y_train)/args.batch_size) + 1

    num_batch_test = int(len(y_test)/args.batch_size) + 1

    last_acc = 0.0

    if args.mode == 'train':

        for epoch in range(args.epoch):
           
            acc = []
            total_loss = 0

            acc_test = []

            model.to(device)
            
            for i in range(num_batch):
                sys.stdout.write('\r{0}/{1}'.format(i, num_batch))
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_train))

                x = X_train[st:ed]
                x = x.transpose(0, 1)
                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))
                x = x.to(device)

                ftr = FTR_train[st:ed]
                ftr = ftr.transpose(0, 1)
                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
                ftr = ftr.to(device)

                label = y_train[st:ed]
                label = label.to(device)

                model.zero_grad()

                output = model(x, ftr)
                output = output.transpose(1, 2)
                output = torch.squeeze(output)

                loss = loss_function(output, label)

                predict_max_idx = torch.max(output, 1)[1]
                label_max_idx = torch.max(label, 1)[1]
                
                acc.append(torch.sum(predict_max_idx == label_max_idx))
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            for i in range(num_batch_test):
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_test))

                x_test = X_test[st:ed]
                x_test = x_test.transpose(0, 1)
                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
                x_test = x_test.to(device)

                ftr_test = FTR_test[st:ed]
                ftr_test = ftr_test.transpose(0, 1)
                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
                ftr_test = ftr_test.to(device)

                label_test = y_test[st:ed]
                label_test = label_test.to(device)

                output_test = model(x_test, ftr_test)
                output_test = output_test.transpose(1, 2)
                output_test = torch.squeeze(output_test)

                predict_max_idx_test = torch.max(output_test, 1)[1]
                label_max_idx_test = torch.max(label_test, 1)[1]
                
                acc_test.append(torch.sum(predict_max_idx_test == label_max_idx_test))
           
            total_loss /= len(y_train)
            acc = sum(acc)*1.0/len(y_train)

            acc_test = sum(acc_test)*1.0/len(y_test)
            if epoch%10 == 0 or epoch == args.epoch - 1:
              print('\nEpoch: ', epoch)
              print('\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))

            scheduler.step() 

            if acc_test > last_acc:
                torch.save(model.cpu(), model_path_city_lstm)
                last_acc = acc_test

#City prediction evaluation LSTM
from sklearn import metrics 
from sklearn.metrics import classification_report, confusion_matrix

model = torch.load(model_path_city_lstm)
model.to(device)
acc_test = []
y_pred = []
y_label = []

for i in range(num_batch_test):
    st = i * args.batch_size
    ed = min((i+1) * args.batch_size, len(y_test))

    x_test = X_test[st:ed]
    x_test = x_test.transpose(0, 1)
    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
    x_test = x_test.to(device)

    ftr_test = FTR_test[st:ed]
    ftr_test = ftr_test.transpose(0, 1)
    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
    ftr_test = ftr_test.to(device)

    label_test = y_test[st:ed]
    label_test = label_test.to(device)

    output_test = model(x_test, ftr_test)
    output_test = output_test.transpose(1, 2)
    output_test = torch.squeeze(output_test)
    
    predict_max_idx_test = torch.max(output_test, 1)[1]
    label_max_idx_test = torch.max(label_test, 1)[1]
    
    y_pred += predict_max_idx_test
    y_label += label_max_idx_test

y_pred = list(map(float, y_pred))
y_pred = np.asarray(y_pred)
y_pred = torch.FloatTensor(y_pred)

y_label = list(map(float, y_label))
y_label = np.asarray(y_label)
y_label = torch.FloatTensor(y_label)

print('City Prediction LSTM Results:')
print("Accuracy:",metrics.accuracy_score(y_label, y_pred))
print(confusion_matrix(y_label, y_pred))
print(classification_report(y_label, y_pred))

#MLP city prediction baseline
from __future__ import print_function
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import argparse
import sys
import math

class MLP(nn.Module):
    def __init__(self, input_size):
        super(MLP, self).__init__()
        self.layer1 = nn.Linear(input_size, 200)
        self.layer2 = nn.Linear(200, 100)

        #three possible outcomes
        self.layer3 = nn.Linear(100, 4)

        self.last_layer = nn.Sigmoid() 
     
    def forward(self, src, ftr):
        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], src.shape[2])

        hidden = torch.cat((src, ftr), 0)

        output = torch.squeeze(hidden)


        output = output.transpose(0, 1)

        output = self.layer1(output)
        output = self.layer2(output)
        output = self.layer3(output)

        output = self.last_layer(output)
        return output

if __name__ == '__main__':
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument('--mode', choices=['train', 'infer'],\
        default='train',help='Run mode')
    arg_parser.add_argument('--epoch', default='30', type=int)
    arg_parser.add_argument('--batch_size', default='32', type=int)
    args = arg_parser.parse_args(args=['--mode', 'train'])
    args = arg_parser.parse_args(args=['--epoch', '30'])
    args = arg_parser.parse_args(args=['--batch_size', '32'])

    model_path_city = PATH + 'MODEL/model_mlp_city.pt'

    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()

    print(X_train.shape)
    print(y_train.shape)
    print(X_test.shape)
    print(y_test.shape)

    model = MLP(input_size = X_train.shape[1] + FTR_train.shape[1])
    #model = MLP(input_size = X_train.shape[1])
    loss_function = nn.MSELoss()

    optimizer = optim.SGD(model.parameters(), lr=0.1)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)

    num_batch = int(len(y_train)/args.batch_size) + 1

    num_batch_test = int(len(y_test)/args.batch_size) + 1

    last_acc = 0.0

    if args.mode == 'train':

        for epoch in range(args.epoch):
           
            acc = []
            total_loss = 0

            acc_test = []

            model.to(device)
            
            for i in range(num_batch):
                sys.stdout.write('\r{0}/{1}'.format(i, num_batch))
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_train))

                x = X_train[st:ed]
                x = x.transpose(0, 1)
                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))
                x = x.to(device)

                ftr = FTR_train[st:ed]
                ftr = ftr.transpose(0, 1)
                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
                ftr = ftr.to(device)

                label = y_train[st:ed]
                label = label.to(device)

                model.zero_grad()

                output = model(x, ftr)
                #predict = torch.squeeze(output)

                loss = loss_function(output, label)

                predict_max_idx = torch.max(output, 1)[1]
                label_max_idx = torch.max(label, 1)[1]

                print('label_max_idx: ',label_max_idx.shape)
                print('label_max_idx: ',label_max_idx)

                acc.append(torch.sum(predict_max_idx == label_max_idx))
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            for i in range(num_batch_test):
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_test))

                x_test = X_test[st:ed]
                x_test = x_test.transpose(0, 1)
                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
                x_test = x_test.to(device)

                ftr_test = FTR_test[st:ed]
                ftr_test = ftr_test.transpose(0, 1)
                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
                ftr_test = ftr_test.to(device)

                label_test = y_test[st:ed]
                label_test = label_test.to(device)


                output_test = model(x_test, ftr_test)

                #predict_test = torch.squeeze(output_test)
                #print("predict test: ", predict_test)
                #print("label test: ", label_test)

                predict_max_idx_test = torch.max(output_test, 1)[1]
                label_max_idx_test = torch.max(label_test, 1)[1]
                

                #print(label_max_idx_test)

                acc_test.append(torch.sum(predict_max_idx_test == label_max_idx_test))
           
            total_loss /= len(y_train)
            acc = sum(acc)*1.0/len(y_train)

            acc_test = sum(acc_test)*1.0/len(y_test)
            #print(acc)
            #print(total_loss)

            
            if epoch%10 == 0 or epoch == args.epoch - 1:
                print('\nEpoch: ', epoch)
                print('\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))

            scheduler.step() 

            if acc_test > last_acc:
                torch.save(model.cpu(), model_path_city)
                last_acc = acc_test

#MLP evaluation
from sklearn import metrics 
from sklearn.metrics import classification_report, confusion_matrix

model = torch.load(model_path_city)
model.to(device)
acc_test = []
y_pred = []
y_label = []

for i in range(num_batch_test):
    st = i * args.batch_size
    ed = min((i+1) * args.batch_size, len(y_test))

    x_test = X_test[st:ed]
    x_test = x_test.transpose(0, 1)
    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
    x_test = x_test.to(device)

    ftr_test = FTR_test[st:ed]
    ftr_test = ftr_test.transpose(0, 1)
    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
    ftr_test = ftr_test.to(device)

    label_test = y_test[st:ed]
    label_test = label_test.to(device)


    output_test = model(x_test, ftr_test)


    predict_max_idx_test = torch.max(output_test, 1)[1]
    label_max_idx_test = torch.max(label_test, 1)[1]

    y_pred += predict_max_idx_test
    y_label += label_max_idx_test

y_pred = list(map(float, y_pred))
y_pred = np.asarray(y_pred)
y_pred = torch.FloatTensor(y_pred)

y_label = list(map(float, y_label))
y_label = np.asarray(y_label)
y_label = torch.FloatTensor(y_label)

print('MLP City Prediction Results:')
print("Accuracy:",metrics.accuracy_score(y_label, y_pred))
print(confusion_matrix(y_label, y_pred))
print(classification_report(y_label, y_pred))
#print(metrics.roc_auc_score(y_test, y_pred))

#Transformer city prediction
from __future__ import print_function
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import argparse
import sys
import math

class PositionalEncoding(nn.Module):

    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()       
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        pe.requires_grad = True
        self.register_buffer('pe', pe)

    def forward(self, x):
        return x + self.pe[:x.size(0), :]

class Transformer(nn.Module):
    def __init__(self, input_size, feature_size=250,num_layers=1,dropout=0.1):
        super(Transformer, self).__init__()
        self.src_mask = None
        self.pos_encoder = PositionalEncoding(feature_size)
        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)
        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)   
    
        
        self.layer = nn.Linear(feature_size,1) 
        #self.layer1 = nn.Linear(input_size, 200)
        self.layer1 = nn.Linear(input_size, 200)
        self.layer2 = nn.Linear(200, 100)
        self.layer3 = nn.Linear(100, 4)

        self.last_layer = nn.Sigmoid()
     
    def forward(self, src, ftr):
        if self.src_mask is None or self.src_mask.size(0) != len(src):
            mask = self._generate_square_subsequent_mask(len(src)).to(device)
            self.src_mask = mask

        src = self.pos_encoder(src)
        hidden = self.transformer_encoder(src,self.src_mask)
        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], hidden.shape[2])
      

        hidden = torch.cat((hidden, ftr), 0)

        output = self.layer(hidden)

        output = torch.squeeze(output)
        output = output.transpose(0, 1)
        #print('shape5', src.shape)
        output = self.layer1(output)
        #print('shape5', src.shape)
        output = self.layer2(output)
        output = self.layer3(output)

        output = self.last_layer(output)
        return output

    def _generate_square_subsequent_mask(self, sz):
        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)
        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))
        return mask
    
    #attention plot to get the dot product
    def scaled_dot_product(q, k, v, mask=None):
        d_k = q.size()[-1]
        attn_logits = torch.matmul(q, k.transpose(-2, -1))
        attn_logits = attn_logits / math.sqrt(d_k)
        if mask is not None:
            attn_logits = attn_logits.masked_fill(mask == 0, -9e15)
        attention = F.softmax(attn_logits, dim=-1)
        values = torch.matmul(attention, v)
        return values, attention


if __name__ == '__main__':
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument('--mode', choices=['train', 'infer'],\
        default='train',help='Run mode')
    arg_parser.add_argument('--epoch', default='100', type=int)
    arg_parser.add_argument('--batch_size', default='32', type=int)
    args = arg_parser.parse_args(args=['--mode', 'train'])
    args = arg_parser.parse_args(args=['--epoch', '100'])
    args = arg_parser.parse_args(args=['--batch_size', '32'])

    model_path_city = PATH + 'MODEL/model_all_city_hotspot_3.pt'

    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()

    print(X_train.shape)
    print(y_train.shape)
    print(X_test.shape)
    print(y_test.shape)


    #choose temporal or census or both
    model = Transformer(input_size = X_train.shape[1] + FTR_train.shape[1])
    #model = Transformer(input_size = X_train.shape[1])
    loss_function = nn.MSELoss()

    optimizer = optim.SGD(model.parameters(), lr=0.1)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)

    num_batch = int(len(y_train)/args.batch_size) + 1

    num_batch_test = int(len(y_test)/args.batch_size) + 1

    last_acc = 0.0

    if args.mode == 'train':

        for epoch in range(args.epoch):
           
            acc = []
            total_loss = 0

            acc_test = []

            model.to(device)
            
            for i in range(num_batch):
                sys.stdout.write('\r{0}/{1}'.format(i, num_batch))
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_train))

                x = X_train[st:ed]
                x = x.transpose(0, 1)
                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))
                x = x.to(device)

                ftr = FTR_train[st:ed]
                ftr = ftr.transpose(0, 1)
                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))
                ftr = ftr.to(device)

                label = y_train[st:ed]
                label = label.to(device)

                model.zero_grad()

                output = model(x, ftr)

                loss = loss_function(output, label)

                predict_max_idx = torch.max(output, 1)[1]
                label_max_idx = torch.max(label, 1)[1]
                
                acc.append(torch.sum(predict_max_idx == label_max_idx))
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            for i in range(num_batch_test):
                st = i * args.batch_size
                ed = min((i+1) * args.batch_size, len(y_test))

                x_test = X_test[st:ed]
                x_test = x_test.transpose(0, 1)
                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
                x_test = x_test.to(device)

                ftr_test = FTR_test[st:ed]
                ftr_test = ftr_test.transpose(0, 1)
                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
                ftr_test = ftr_test.to(device)

                label_test = y_test[st:ed]
                label_test = label_test.to(device)

                output_test = model(x_test, ftr_test)

                predict_max_idx_test = torch.max(output_test, 1)[1]
                label_max_idx_test = torch.max(label_test, 1)[1]
                
                acc_test.append(torch.sum(predict_max_idx_test == label_max_idx_test))
           
            total_loss /= len(y_train)
            acc = sum(acc)*1.0/len(y_train)

            acc_test = sum(acc_test)*1.0/len(y_test)
            if epoch%10 == 0 or epoch == args.epoch - 1:
              print('\nEpoch: ', epoch)
              print('\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))

            scheduler.step() 

            if acc_test > last_acc:
                torch.save(model.cpu(), model_path_city)
                last_acc = acc_test

#City prediction evaluation
from sklearn import metrics 
from sklearn.metrics import classification_report, confusion_matrix

model = torch.load(model_path_city)
model.to(device)
acc_test = []
y_pred = []
y_label = []

for i in range(num_batch_test):
    st = i * args.batch_size
    ed = min((i+1) * args.batch_size, len(y_test))

    x_test = X_test[st:ed]
    x_test = x_test.transpose(0, 1)
    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
    x_test = x_test.to(device)

    ftr_test = FTR_test[st:ed]
    ftr_test = ftr_test.transpose(0, 1)
    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))
    ftr_test = ftr_test.to(device)

    label_test = y_test[st:ed]
    label_test = label_test.to(device)

    output_test = model(x_test, ftr_test)
    
    predict_max_idx_test = torch.max(output_test, 1)[1]
    label_max_idx_test = torch.max(label_test, 1)[1]
    
    y_pred += predict_max_idx_test
    y_label += label_max_idx_test

y_pred = list(map(float, y_pred))
y_pred = np.asarray(y_pred)
y_pred = torch.FloatTensor(y_pred)

y_label = list(map(float, y_label))
y_label = np.asarray(y_label)
y_label = torch.FloatTensor(y_label)

print('City Prediction Results:')
print("Accuracy:",metrics.accuracy_score(y_label, y_pred))
print(confusion_matrix(y_label, y_pred))
print(classification_report(y_label, y_pred))
#skplt.metrics.plot_confusion_matrix(y_label, y_pred, normalize=True)  
#plt.savefig(PATH+'test_metric.png', dpi=300)